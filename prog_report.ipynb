{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "BCukm9U9AFGH"
      },
      "source": [
        "### Project Introduction\n",
        "\n",
        "Our project focuses around how different music affects the mood of different listeners. The data set that we have chosen tracks the mood of listeners for various different songs. It also keeps track of other details and features of the songs, such as length, tempo, key, time signature, and popularity. Our group aims to find which of these key characteristics can best determine whether or not a listener will experience a positive or negative mood in response. With the data we can also see temporal trends, and perhaps see if there are any time periods that caused a change in trend for music mood and how they correlate to the events going on in the world.\n",
        "\n",
        "Link to github repo for the progress report: https://github.com/uic-ds-fall-2023/class-project-next-level-analytics/blob/main/prog_report.ipynb"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "tlePx_prAFGK"
      },
      "source": [
        "The dataset has the following columns:\n",
        "- name\n",
        "- album\n",
        "- artist\n",
        "- id\n",
        "- release date\n",
        "- popularity\n",
        "- length\n",
        "- danceability\n",
        "- acousticness\n",
        "- energy\n",
        "- instrumentalness\n",
        "- liveness\n",
        "- valence\n",
        "- loudness\n",
        "- speechiness\n",
        "- tempo\n",
        "- key\n",
        "- time signature\n",
        "- mood"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ZvoRb9-YAFGL"
      },
      "source": [
        "Any changes: After speaking with the professor, we decided to use a publicly available dataset that has much more data points that we are able to study. The link to the dataset can be found here: https://www.kaggle.com/datasets/musicblogger/spotify-music-data-to-identify-the-moods/data\n",
        "\n",
        "Due to the change in the dataset that we are using, we have slightly altered the domain questions/hypotheses and scope of our initial project idea that we were aiming to explore and answer. We are now more focused on how key features of the songs that we are listening can impact the mood, such as key and time signature, rather than something as broad as using a song's genre, time spent listening to music, and age range to dictate these outcomes."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "VsX3EXH3AFGL"
      },
      "source": [
        "### Data Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "bm_vipmZAFGL"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'sklearn'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\dmarc\\OneDrive\\Documents\\GitHub\\class-project-next-level-analytics\\prog_report.ipynb Cell 5\u001b[0m line \u001b[0;36m6\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/dmarc/OneDrive/Documents/GitHub/class-project-next-level-analytics/prog_report.ipynb#W4sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mseaborn\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39msns\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/dmarc/OneDrive/Documents/GitHub/class-project-next-level-analytics/prog_report.ipynb#W4sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/dmarc/OneDrive/Documents/GitHub/class-project-next-level-analytics/prog_report.ipynb#W4sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m \u001b[39mimport\u001b[39;00m svm, metrics\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
          ]
        }
      ],
      "source": [
        "# import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import svm, metrics"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "wPFcm7HEAFGM",
        "outputId": "6594660a-d2f9-4476-84f5-3b52e3ead9ed"
      },
      "outputs": [],
      "source": [
        "# read in the data file\n",
        "music_data = pd.read_csv('data_moods.csv')\n",
        "\n",
        "# clean data to include specific columns, exclude subjective columns such as \"danceability\"\n",
        "music_data = music_data[['name', 'album', 'artist', 'id', 'release_date', 'popularity', 'tempo', 'key', 'time_signature', 'mood']]\n",
        "\n",
        "# now remove any rows with n/a values\n",
        "music_data = music_data.dropna()\n",
        "\n",
        "# display the first five entries\n",
        "music_data.head()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "xnydNCacAFGN"
      },
      "source": [
        "### Exploratory Data Analysis"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "FtUrsnk5AFGN"
      },
      "source": [
        "Some interesting issues or thoughts on the data is how the data considers various features to affect the moods that people feel about different music. These include aspects such as tempo, time signature of the musical piece, the key the musical piece is played at, the overall popularity number associated the particular musical piece, and the date when the musical piece was released. Based on looking at the data after cleaning it, it appears that key and tempo change across different musical pieces while time signuature appears to be commonly 4 beats per measure but this value is not consistently 4 beats per measure for all songs recorded. There also seem to be different moods present but the Happy and Sad moods seem to be the most useful as they are opposites and can provide greater insights into individual's personal feelings for a song.\n",
        "\n",
        "Based on the data explored and learned about from the below code, it can be possible to make some preliminary conclusions. It appears that songs that invoke feelings of happiness are often caused to make people feel good about themselves and to emphasize such feelings of joy are generally played at faster tempos. This is indicated below with the average tempo of happy songs are more quicker compared to sad songs. In general, people tend to want to feel happy so happy or feel-good songs tend to be more popular across individuals compared to sad songs. This is also indicated below with the average popularity of happy songs being greater than sad songs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BFJ0iQEsAFGN",
        "outputId": "11bad82a-e9e8-4ac3-fcf2-207d7f8e2327"
      },
      "outputs": [],
      "source": [
        "print(\"Descriptive Statistics of the Music Data: \")\n",
        "print(music_data.describe())\n",
        "print()\n",
        "print(\"The average tempo across all songs: \")\n",
        "print(music_data['tempo'].mean())\n",
        "print()\n",
        "print(\"Average tempo of happy songs:\")\n",
        "happy_songs = music_data[music_data['mood'] == 'Happy']\n",
        "print(happy_songs['tempo'].mean())\n",
        "print()\n",
        "print(\"Average popularity of happy songs: \")\n",
        "print(happy_songs['popularity'].mean())\n",
        "print()\n",
        "print(\"Average tempo of sad songs:\")\n",
        "sad_songs = music_data[music_data['mood'] == 'Sad']\n",
        "print(sad_songs['tempo'].mean())\n",
        "print()\n",
        "print(\"Average popularity of sad songs: \")\n",
        "print(sad_songs['popularity'].mean())\n",
        "print()\n",
        "print(\"Grouping of years and count of the moods present for that year: \")\n",
        "data = pd.to_datetime(music_data['release_date'], errors='coerce', utc=True).dt.strftime('%Y')\n",
        "music_data['year'] = data\n",
        "music_data.groupby(['year', 'mood'])['mood'].count()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "-Eiw_L_UAFGO"
      },
      "source": [
        "### Visualizations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        },
        "id": "VLzaKp9JAFGO",
        "outputId": "4871e441-9018-4dcc-a653-c1917cfb133c"
      },
      "outputs": [],
      "source": [
        "# visualization 1\n",
        "# barchart for comparison between moods and popularity with time signature hue\n",
        "ax = sns.barplot(data = music_data, x = 'mood', y = 'popularity', hue = 'time_signature', palette = 'flare')\n",
        "ax.set(ylabel = 'Popularity', xlabel = 'Mood', title = 'Song Popularity Based on Mood and Time Signature')\n",
        "plt.legend(title = 'Time Signature\\n(Beats per Measure)', bbox_to_anchor = (1, 0.50), loc = 'upper left')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "yrpD2mwCtHME"
      },
      "source": [
        "Description: The visualization above shows a barchart detailing the popularity of different moods. There is an added factor of showing the time signature of these songs as well. We can see that for calm or happy music, the time signature does not make too much of an impact on how popular those songs end up being.\n",
        "\n",
        "We can see that for energetic music, there are no songs with the time signature of 1 or 5. This can lead us to conclude that a consistent and relatively faster time signature is key to music being categorized as \"energetic\". The same can be said for happy music. We can explore the data further and see if happy and energetic music falls under some sort of \"formula\" - we can see if other factors of the song such as tempo follow similar guidelines.\n",
        "\n",
        "Sad and calm music have more variability in their time signature, and it is clear from the visualization that sad music has the most. Sad songs trend more towards the edges of the time signature domain, most songs either having a time signature of 1 or 5."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 526
        },
        "id": "0fD6Wo11AFGO",
        "outputId": "f75f9c4f-9114-483b-df4c-8bad91e40686"
      },
      "outputs": [],
      "source": [
        "# visualization 2\n",
        "# boxplot for comparison between tempo of the music and moods\n",
        "ax = sns.boxplot(data = music_data, x = 'tempo', y = 'mood', hue = 'mood', palette = 'icefire')\n",
        "ax.set(ylabel = 'Mood', xlabel = 'Tempo (Beats Per Min)', title = 'Song Tempo Dictated By Different Moods')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "0RM9cjg_AFGO"
      },
      "source": [
        "**Interesting Hypothesis Explanation**\n",
        "\n",
        "The interesting hypothesis considered here is thinking about how tempo is affected based on the moods that the particular songs invoke. Various moods (happy, sad, energetic, or calm) have different levels or speeds the musical piece is played to portray the overall song's atmosphere.\n",
        "\n",
        "**Why this is an interesting hypothesis to investigate?**\n",
        "\n",
        "This was an interesting hypothesis to investigate to consider one of the important factors that contribute to why people feel a certain way towards particular songs. The tempo of the song can alter how the song makes an individual feel and can be interesting to observe this dynamic visually. For that, it was fascinating to consider this idea and investigate affects of tempo on moods pertaining to different songs\n",
        "\n",
        "**Interesting Graph Insights**\n",
        "\n",
        "The key things that appear evident at first glance is that there are outliers present for the happy and calm moods. This may mean that tempos have drastically differing values outside of the 5-number summary for songs invoking feelings of happiness and calmness. Other noticeable things is that happy and energetic songs have higher medians compared to the sad and calm songs. The range of tempos for sad, energetic, and calm songs are more than happy songs. This could be that happy songs fall within a subset of tempos to achieve happiness in the song. It also appears to be that songs that are sad or calm are more slower to create sorrowful or serene tones which are not played at quick speeds but lower tempos. This can be observed with the lower quartile of sad and calm songs being 50 to 100 beats per minute. In contrast, energetic and happy songs have a higher quartile range between 75 to 125 beats per minute."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "WDAfVDtZAFGO"
      },
      "source": [
        "### Machine Learning Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OC-JxWoAAFGP",
        "outputId": "ed7615b0-699d-47b2-d7b7-54584cd411ad"
      },
      "outputs": [],
      "source": [
        "# Machine Learning Analysis 1\n",
        "# Determine the mood of the song (happy/sad/energetic/calm) based on popularity\n",
        "\n",
        "# Split test and train data\n",
        "X = music_data['popularity']\n",
        "y = music_data['mood']\n",
        "\n",
        "X_train = X[:620]\n",
        "X_test = X[620:]\n",
        "\n",
        "y_train = y[:620]\n",
        "y_test = y[620:]\n",
        "\n",
        "# Convert both the X_train and X_test to 2D arrays\n",
        "X_train = X_train.values.reshape(-1, 1)\n",
        "X_test = X_test.values.reshape(-1, 1)\n",
        "\n",
        "# Convert both y_train and y_test to lists\n",
        "y_train = y_train.tolist()\n",
        "y_test = y_test.tolist()\n",
        "\n",
        "# Baseline comparision\n",
        "freq_dict = {}\n",
        "\n",
        "for i in y:\n",
        "  freq_dict.setdefault(i, 0)\n",
        "  freq_dict[i] += 1\n",
        "\n",
        "max_freq = max(freq_dict.values())\n",
        "max_freq_lst = []\n",
        "\n",
        "for k, v in freq_dict.items():\n",
        "  if v == max_freq:\n",
        "    max_freq_lst.append(k)\n",
        "\n",
        "mode = max_freq_lst[0]\n",
        "\n",
        "labels = [mode] * X.shape[0]\n",
        "\n",
        "correct_pred_cnt = 0\n",
        "\n",
        "for i in range(len(labels)):\n",
        "  if labels[i] == y[i]:\n",
        "    correct_pred_cnt += 1\n",
        "\n",
        "training_accuracy = correct_pred_cnt/len(y)\n",
        "print(\"Training accuracy for baseline is: \", training_accuracy)\n",
        "\n",
        "# Actual model\n",
        "\n",
        "clf = svm.SVC(gamma = 'scale', kernel = 'rbf')\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "y_pred = clf.predict(X_test)\n",
        "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
        "print(\"Training accuracy for svm is: \", accuracy)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "6c1lyvYAAFGP"
      },
      "source": [
        "**(Shreya)**\n",
        "Obtained Result Interpretation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJtMXk0aAFGP",
        "outputId": "f7ee956e-50c6-48d7-c6b0-9351fe877c19"
      },
      "outputs": [],
      "source": [
        "# Machine Learning Analysis 2\n",
        "# Determine the mood of the song (happy/sad/energetic/calm) based on tempo\n",
        "\n",
        "X = music_data['tempo']\n",
        "y = music_data['mood']\n",
        "\n",
        "# split data for train and test data with 80%/20%\n",
        "# length = len(X)\n",
        "# indices = np.random_permutation(length)\n",
        "# traini = indices[:int(math.ceil(length*0.8))]\n",
        "\n",
        "xtrain = X[:620]\n",
        "xtest = X[620:]\n",
        "\n",
        "ytrain = y[:620]\n",
        "ytest = y[620:]\n",
        "\n",
        "# Convert both the X_train and X_test to 2D arrays\n",
        "xtrain = xtrain.values.reshape(-1, 1)\n",
        "xtest = xtest.values.reshape(-1, 1)\n",
        "\n",
        "# Convert both y_train and y_test to lists\n",
        "ytrain = ytrain.tolist()\n",
        "ytest = ytest.tolist()\n",
        "\n",
        "# Baseline comparison\n",
        "from statistics import mode\n",
        "mode = mode(y)\n",
        "pred = [mode] * X.shape[0]\n",
        "training_accuracy = (pred == y).mean()\n",
        "print(\"Training accuracy for baseline is: \", training_accuracy)\n",
        "\n",
        "# Actual model\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "knn = KNeighborsClassifier(n_neighbors = 5)\n",
        "knn.fit(xtrain, ytrain)\n",
        "predict = knn.predict(xtest)\n",
        "acc = knn.score(xtest, ytest)\n",
        "print(\"Training accuracy for 5-KNN: \", acc)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "dBY3FOHHAFGP"
      },
      "source": [
        "**Obtained Result Interpretation**\n",
        "\n",
        "The training accuracy for the 5-KNN model is better than the training accuracy for the baseline model. The 5-KNN model is also the best KNN model compared to the other KNN models (such as 1-KNN, 3-KNN, 7-KNN, etc). Compared to the results from the first machine learning model, however, the 5-KNN model isn't the best model to train the current data. A way to improve the training accuracy would be to shuffle the data before fitting the train data to the model and predicting the test data."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "c0HxeX9MAFGP"
      },
      "source": [
        "### Reflection\n",
        "\n",
        "**What is the hardest part of the project that you’ve encountered so far?**\n",
        "\n",
        "The hardest part of the project was to try to find a useful dataset or data source that can help us find meaningful insights on what causes people to feel certain ways when listening to different musical genres while considering how this can affect their mental health/well-being. At first, we have created google surveys to collect data on a person's age group, how a set of musical genres makes them feel one of three ways (positive, neutral, or negative), and if those musical genre selection affect their mental health/well-being. This data was limited in scope as these factors are not enough to draw meaningful conclusions from so we decided to use another dataset pertaining to music. This data was more useful as there were other useful factors since as time, key, time signature, tempo, popularity, and moods which was what we wanted to address as a group. Other difficult aspects of the project was finding useful insights on the data to help make informed conclusions on addressing our initial poroblem. This meant observing and cleaning the data to better help us make meaningful visualizations and develop useful ML models. Finding those factors and fidning relationships that were relevant such as popularity, time signature, and tempo of a song to the moods was not simple.\n",
        "\n",
        "**What are your initial insights?**\n",
        "\n",
        "From the data, the initial insights are that various moods (happy, sad, energetic, and calm) are influenced based on some key features of songs. These include the song's tempo, key, time signature, and popularity. From the exploratory data analysis and visualizations, it can observed that songs that invoke feelings of happiness and are energetic are played at faster tempos and are only played with a 3 or 4 time signatures (beats per measure). In contrast, sad and calm songs are played at 1, 3, 4, 5 time signature with more time signature variability but played at slower tempos. However, though the EDA may show that average popularity was more for happier songs than sad songs the time signature says otherwise. The first visualization shows that sad songs with 5 beats per measure have large following as the popularity is much greater than all other mood and time signature combinations presented in this graph.\n",
        "\n",
        "**(Darlene)**\n",
        "\n",
        "**Are there any concrete results you can show at this point? If not, why not?**\n",
        "\n",
        "So far based on the dataset we have cleaned up we were able to identify some patterns and correlations between the moods and musical features like the perceived mood of the songs. Some concrete results we discussed are finding the descriptive statistics and visualizations so far. This led us to make some hypotheses, for instance, we saw there was an average tempo across all songs like happy ones, and sad ones. Which sad ones had a higher rate at 115.59. We concluded that faster tempos meant that people could potentially be because of some songs that evoke feelings of happiness. We also designed some visualizations in the bar chart that had some interesting patterns but also outliers, this bar chart displayed different moods based on popularity which led us to make some hypotheses that this can be from the tempo a factor we can look more into that can determine why a person can feel a certain way towards certain songs. \n",
        "\n",
        "\n",
        "**(Darlene)**\n",
        "\n",
        "**Going forward, what are the current biggest problems you’re facing?**\n",
        "\n",
        "In the beginning, we collected our initial data through Google Forms and got a good number of responses but we noticed that data was limited so that is why we chose to explore other public datasets that were available it was a problem before now we have found a solution for it. With the new data set, we were able to design some visualizations to get a better understanding of the data we have. Currently, we have yet to make any big test to support our hypothesis, we did discuss the potential use of a 5-KNN model but we can explore other approaches to see if we can get answers. Another thing is that we should look deeper into our data if any limitations might affect our results so we can perform more tests just to make sure our data is diverse and have a wide range of features we can use whether it is the genres or other demographics. Not sure if the complexity of mood is too complex or if we should consider incorporating external factors that can either involve choosing songs with specific moods or how it influences so it is something to keep in mind. \n",
        "\n",
        "\n",
        "**(Shreya)**\n",
        "\n",
        "**Do you think you are on track with your project? If not, what parts do you need to dedicate more time to?**\n",
        "\n",
        "**(Shreya)**\n",
        "\n",
        "**Given your initial exploration of the data, is it worth proceeding with your project, why?**\n",
        "\n",
        "\n",
        "**If not, how are you going to change your project and why do you think it’s better than your current results?**\n",
        "\n",
        "To improve the data that we currently have, it would be better to collect our own sample data while asking the same questions that the dataset we found did. We could mix the sample data we collect with the current data to get a wider and an unbiased audience. Another change that we could make within the machine learning models to improve the test accuracy would be to shuffle the data beforehand and split the data 80% train data and 20% test data. All these changes would imporve our current results because it would remove biases and randomizing the data before training and testig it would improve accuracies and results."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "NepynCn7AFGP"
      },
      "source": [
        "### Next Steps\n",
        "\n",
        "**What you plan to accomplish in the next month and how you plan to evaluate whether your project achieved the goals you set for it.**\n",
        "\n",
        "In the next month, we will be aiming to improve the training accuracies and finalizing any more of the visualizations. We will also be working on adding more visualizations and more machine learning models. We will also try to find more datasets as well to improve the bias that might exist in the one dataset that we are using right now. "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
